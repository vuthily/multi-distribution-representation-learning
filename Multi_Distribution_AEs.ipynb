{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim import fully_connected as fc\n",
    "import matplotlib.pyplot as plt \n",
    "import readdata\n",
    "import operator\n",
    "import os.path\n",
    "import classifier\n",
    "from  sklearn.metrics  import  accuracy_score , roc_curve , auc , roc_auc_score\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model configurations\n",
    "hidden_layers = np.asarray([[85, 30, 15], [150, 100,50],[30,20,10],[1000,500,100],\n",
    "                            [50,30,15],[450,200,100],[35,20,10],[85, 30, 15]])\n",
    "batch_sizes = np.asarray([100,100,100,100,100,100,100,100])\n",
    "data_index = 7\n",
    "dataname = datasets[data_index]\n",
    "hidden_layer = hidden_layers[data_index]\n",
    "batch_size = batch_sizes [data_index]\n",
    "\n",
    "dt = readdata.read_data_sets(dataname)\n",
    "num_sample = dt.train.num_examples\n",
    "\n",
    "print (\"size of dataset: \",num_sample)\n",
    "input_dim = dt.train.features.shape[1]\n",
    "\n",
    "label_dim = dt.train.labels.shape[1]\n",
    "\n",
    "print (\"dimension: \",input_dim)\n",
    "print  (\"number of class: \",label_dim)\n",
    "\n",
    "\n",
    "data_save = np.asarray([data_index, input_dim,  label_dim])   \n",
    "data_save = np.reshape(data_save, (-1,3))\n",
    "\n",
    "\n",
    "if os.path.isfile(\"Results/datainformation.csv\"): #\n",
    "    auc = np.genfromtxt('Results/datainformation.csv', delimiter=',') \n",
    "    auc = np.reshape(auc,(-1,3))\n",
    "    data_save = np.concatenate((auc, data_save), axis = 0)\n",
    "    np.savetxt(\"Results/datainformation.csv\", data_save,delimiter = \",\",fmt = \"%f\")\n",
    "    \n",
    "else:\n",
    "    np.savetxt(\"Results/datainformation.csv\", data_save,delimiter = \",\",fmt = \"%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dt.train.features\n",
    "Y_train = dt.train.labels\n",
    "\n",
    "X_test = dt.test.features\n",
    "Y_test = dt.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(object):\n",
    "\n",
    "    def __init__(self, learning_rate=1e-3, batch_size=100, hidden_layers = [85, 30,12]):\n",
    "       \n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.build()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Build the netowrk and the loss functions\n",
    "    def build(self):\n",
    "        self.x = tf.placeholder(name='x', dtype=tf.float32, shape=[None, input_dim])\n",
    "        \n",
    "        # Encode\n",
    "        # x -> z_mean, z_sigma -> z\n",
    "        f1 = fc(self.x, self.hidden_layers[0], scope='ae_enc_fc1', activation_fn=tf.nn.relu)\n",
    "        #f2 = fc(f1, 60, scope='enc_fc2', activation_fn=tf.nn.tanh)\n",
    "        f3 = fc(f1, self.hidden_layers[1], scope='ae_enc_fc3', activation_fn=tf.nn.relu)\n",
    "        #f4 = fc(f3, 20, scope='enc_fc4', activation_fn=tf.nn.relu)\n",
    "        \n",
    "        self.z = fc(f3, self.hidden_layers[2], scope='ae_enc_fc5_mu', activation_fn=None)\n",
    "       \n",
    "        # Decode\n",
    "        # z,y -> x_hat\n",
    "        # g1 = fc(self.Z, 20, scope='dec_fc1', activation_fn=tf.nn.relu)\n",
    "        g2 = fc(self.z,self.hidden_layers[1], scope='ae_dec_fc2', activation_fn=tf.nn.relu)\n",
    "        g3 = fc(g2, self.hidden_layers[0], scope='ae_dec_fc3', activation_fn=tf.nn.relu)\n",
    "        #g4 = fc(g3, 85, scope='dec_fc4', activation_fn=tf.nn.tanh)\n",
    "       \n",
    "        self.x_hat = fc(g3, input_dim, scope='ae_dec_fc5', activation_fn=tf.sigmoid)\n",
    "        #self.x_res = self.x_hat[:,0:input_dim]\n",
    "\n",
    "        # Loss\n",
    "        # Reconstruction loss\n",
    "        recon_loss = tf.reduce_mean(tf.square(self.x - self.x_hat),1) \n",
    "        self.recon_loss = tf.reduce_mean(recon_loss)\n",
    "\n",
    "        self.train_op = tf.train.AdamOptimizer(\n",
    "            learning_rate=self.learning_rate).minimize(self.recon_loss)\n",
    "       \n",
    "        return\n",
    "\n",
    "    # Execute the forward and the backward pass\n",
    "    def run_single_step(self, x):\n",
    "       \n",
    "        _, recon_loss = self.sess.run(\n",
    "            [self.train_op,  self.recon_loss],\n",
    "            feed_dict={self.x: x}\n",
    "           \n",
    "        )\n",
    "      \n",
    "        return recon_loss\n",
    "    # x -> x_hat\n",
    "    def reconstructor(self, x):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.x: x})\n",
    "        return x_hat\n",
    "\n",
    "    # z -> x\n",
    "    def generator(self, z):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.z: z})\n",
    "        return x_hat\n",
    "    \n",
    "    # x -> z\n",
    "    def transformer(self, x):\n",
    "        z = self.sess.run(self.z, feed_dict={self.x: x})\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAE(object):\n",
    "\n",
    "    def __init__(self, learning_rate=1e-3, batch_size=100, hidden_layers = [85, 30,12]):\n",
    "       \n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.build()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Build the netowrk and the loss functions\n",
    "    def build(self):\n",
    "        self.x = tf.placeholder(name='x', dtype=tf.float32, shape=[None, input_dim])\n",
    "        self.y = tf.placeholder(name='y', dtype=tf.float32, shape=[None, label_dim])\n",
    "        \n",
    "        self.Y1 = tf.placeholder(name='Y1', dtype=tf.float32, shape=[None, self.hidden_layers[2]])\n",
    "        self.Y = tf.arg_max(self.y, 1)\n",
    "        self.Y_ = tf.to_float(self.Y)\n",
    "        self.Y1 = tf.expand_dims(self.Y_, 1)\n",
    "        self.Y1 = self.Y1 + 2.0\n",
    "       \n",
    "        # Encode\n",
    "        # x -> z_mean, z_sigma -> z\n",
    "        f1 = fc(self.x, self.hidden_layers[0], scope='mae_enc_fc1', activation_fn=tf.nn.relu)\n",
    "        #f2 = fc(f1, 60, scope='enc_fc2', activation_fn=tf.nn.tanh)\n",
    "        f3 = fc(f1, self.hidden_layers[1], scope='mae_enc_fc3', activation_fn=tf.nn.relu)\n",
    "        \n",
    "        \n",
    "        self.z = fc(f3, self.hidden_layers[2], scope='mae_enc_fc5_mu', activation_fn=None)\n",
    "       \n",
    "        # Decode\n",
    "        # z,y -> x_hat      \n",
    "        g2 = fc(self.z,self.hidden_layers[1], scope='mae_dec_fc2', activation_fn=tf.nn.relu)\n",
    "        g3 = fc(g2, self.hidden_layers[0], scope='mae_dec_fc3', activation_fn=tf.nn.relu)\n",
    "              \n",
    "        self.x_hat = fc(g3, input_dim, scope='mae_dec_fc5', activation_fn=tf.sigmoid)\n",
    "       \n",
    "\n",
    "        # Loss\n",
    "        # Reconstruction loss\n",
    "        # Minimize the cross-entropy loss\n",
    "        recon_loss = tf.reduce_mean(tf.square(self.x - self.x_hat),1) #(((self.x - y)**2).mean(1)).mean()\n",
    "        label_loss = tf.reduce_mean(tf.square(self.z - self.Y1),1)\n",
    "        self.recon_loss = tf.reduce_mean(recon_loss)\n",
    "        self.label_loss = tf.reduce_mean(label_loss)\n",
    "        self.total_loss = recon_loss + label_loss\n",
    "\n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.total_loss)  \n",
    "       \n",
    "        return\n",
    "\n",
    "    # Execute the forward and the backward pass\n",
    "    def run_single_step(self, x, y):\n",
    "       \n",
    "        _, recon_loss, label_loss = self.sess.run(\n",
    "            [self.train_op,  self.recon_loss, self.label_loss],\n",
    "            feed_dict={self.x: x, self.y: y}\n",
    "           \n",
    "        )\n",
    "      \n",
    "        return recon_loss, label_loss\n",
    "    # x -> x_hat\n",
    "    def reconstructor(self, x):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.x: x})\n",
    "        return x_hat\n",
    "\n",
    "    # z -> x\n",
    "    def generator(self, z):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.z: z})\n",
    "        return x_hat\n",
    "    \n",
    "    # x -> z\n",
    "    def transformer(self, x):\n",
    "        z = self.sess.run(self.z, feed_dict={self.x: x})\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMAE(object):\n",
    "\n",
    "    def __init__(self, learning_rate=1e-3, batch_size=100, hidden_layers = [85, 30,12]):\n",
    "       \n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.build()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Build the netowrk and the loss functions\n",
    "    def build(self):\n",
    "        self.x = tf.placeholder(name='dx', dtype=tf.float32, shape=[None, input_dim])\n",
    "        self.y = tf.placeholder(name='dy', dtype=tf.float32, shape=[None, label_dim])\n",
    "        \n",
    "        self.Y1 = tf.placeholder(name='dY1', dtype=tf.float32, shape=[None, self.hidden_layers[2]])\n",
    "        self.Y = tf.arg_max(self.y, 1)\n",
    "        self.Y_ = tf.to_float(self.Y)\n",
    "        self.Y1 = tf.expand_dims(self.Y_, 1)\n",
    "        self.Y1 = self.Y1 + 2.0\n",
    "       \n",
    "        # Encode\n",
    "        # x -> z_mean, z_sigma -> z\n",
    "        X_noise = self.x + self.noise_factor * tf.random_normal(tf.shape(self.x))\n",
    "        X_noise = tf.clip_by_value(X_noise, 0., 1.)\n",
    "\n",
    "        # x -> z_mean, z_sigma -> z\n",
    "        f1 = fc(X_noise, self.hidden_layers[0], scope='dmae_enc_fc1', activation_fn=tf.nn.relu)\n",
    "        #f2 = fc(f1, 60, scope='enc_fc2', activation_fn=tf.nn.tanh)\n",
    "        f3 = fc(f1, self.hidden_layers[1], scope='dmae_enc_fc3', activation_fn=tf.nn.relu)\n",
    "        \n",
    "        \n",
    "        self.z = fc(f3, self.hidden_layers[2], scope='dmae_enc_fc5_mu', activation_fn=None)\n",
    "       \n",
    "        # Decode\n",
    "        # z,y -> x_hat      \n",
    "        g2 = fc(self.z,self.hidden_layers[1], scope='dmae_dec_fc2', activation_fn=tf.nn.relu)\n",
    "        g3 = fc(g2, self.hidden_layers[0], scope='dmae_dec_fc3', activation_fn=tf.nn.relu)\n",
    "              \n",
    "        self.x_hat = fc(g3, input_dim, scope='dmae_dec_fc5', activation_fn=tf.sigmoid)\n",
    "       \n",
    "\n",
    "        # Loss\n",
    "        # Reconstruction loss\n",
    "        # Minimize the cross-entropy loss\n",
    "        recon_loss = tf.reduce_mean(tf.square(self.x - self.x_hat),1) \n",
    "        label_loss = tf.reduce_mean(tf.square(self.z - self.Y1),1)\n",
    "        self.recon_loss = tf.reduce_mean(recon_loss)\n",
    "        self.label_loss = tf.reduce_mean(label_loss)\n",
    "        self.total_loss = recon_loss + label_loss\n",
    "\n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.total_loss)  \n",
    "       \n",
    "        return\n",
    "\n",
    "    # Execute the forward and the backward pass\n",
    "    def run_single_step(self, x, y):\n",
    "       \n",
    "        _, recon_loss, label_loss = self.sess.run(\n",
    "            [self.train_op,  self.recon_loss, self.label_loss],\n",
    "            feed_dict={self.x: x, self.y: y}\n",
    "           \n",
    "        )\n",
    "      \n",
    "        return recon_loss, label_loss\n",
    "    # x -> x_hat\n",
    "    def reconstructor(self, x):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.x: x})\n",
    "        return x_hat\n",
    "\n",
    "    # z -> x\n",
    "    def generator(self, z):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.z: z})\n",
    "        return x_hat\n",
    "    \n",
    "    # x -> z\n",
    "    def transformer(self, x):\n",
    "        z = self.sess.run(self.z, feed_dict={self.x: x})\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVAE(object):\n",
    "\n",
    "    def __init__(self, learning_rate=1e-3, batch_size=100, hidden_layers = [80, 30, 15]):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.build()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Build the netowrk and the loss functions\n",
    "    def build(self):\n",
    "        self.x = tf.placeholder(name='x', dtype=tf.float32, shape=[None, input_dim])\n",
    "        self.y = tf.placeholder(name='y', dtype=tf.float32, shape=[None, label_dim])\n",
    "        \n",
    "        self.X = tf.placeholder(name='X', dtype=tf.float32, shape=[None, input_dim+label_dim])\n",
    "        self.Y1 = tf.placeholder(name='Y1', dtype=tf.float32, shape=[None, self.hidden_layers[2]])\n",
    "        self.X = tf.concat(axis=1, values=[self.x, self.y])\n",
    "        self.Y = tf.arg_max(self.y, 1)\n",
    "        self.Y_ = tf.to_float(self.Y)\n",
    "        self.Y1 = tf.expand_dims(self.Y_, 1)\n",
    "        self.Y1 = (self.Y1 + 1.0)*2\n",
    "\n",
    "      # Encode\n",
    "        # x -> z_mean, z_sigma -> z\n",
    "        f1 = fc(self.x, self.hidden_layers[0], scope='mvae_enc_fc1', activation_fn=tf.nn.relu)\n",
    "       \n",
    "        f3 = fc(f1, self.hidden_layers[1], scope='mvae_enc_fc3', activation_fn=tf.nn.relu)\n",
    "       \n",
    "        self.z_mu = fc(f3, self.hidden_layers[2], scope='mvae_enc_fc5_mu', activation_fn=None)\n",
    "        self.z_log_sigma_sq = fc(f3, self.hidden_layers[2], scope='mvae_enc_fc5_sigma', activation_fn=None)\n",
    "        eps = tf.random_normal(shape=tf.shape(self.z_log_sigma_sq),\n",
    "                               mean=0, stddev=1, dtype=tf.float32)\n",
    "        self.z = self.z_mu + tf.sqrt(tf.exp(self.z_log_sigma_sq)) * eps\n",
    "\n",
    "        # Decode\n",
    "        # z,y -> x_hat\n",
    "        g2 = fc(self.z,self.hidden_layers[1], scope='mvae_dec_fc2', activation_fn=tf.nn.relu)\n",
    "        g3 = fc(g2, self.hidden_layers[0], scope='mvae_dec_fc3', activation_fn=tf.nn.relu)\n",
    "           \n",
    "        self.x_hat = fc(g3, input_dim, scope='mvae_dec_fc5', activation_fn=tf.sigmoid)\n",
    "\n",
    "        # Loss\n",
    "        # Reconstruction loss\n",
    "        # Minimize the mean square error\n",
    "        recon_loss = tf.reduce_mean(tf.square(self.x - self.x_hat),1) \n",
    "        self.recon_loss = tf.reduce_mean(recon_loss)\n",
    "       \n",
    "        #MVAE _latent loss\n",
    "        latent_loss = -0.5*tf.reduce_mean(\n",
    "            self.z_log_sigma_sq - tf.square(self.z_mu - self.Y1)\n",
    "            - tf.exp(self.z_log_sigma_sq) + 1, axis=1)\n",
    "       \n",
    "        self.latent_loss =1000*tf.reduce_mean(latent_loss)\n",
    "            \n",
    "        self.total_loss = recon_loss +latent_loss\n",
    "        self.train_op = tf.train.AdamOptimizer(\n",
    "            learning_rate=self.learning_rate).minimize(self.total_loss)\n",
    "       \n",
    "        return\n",
    "\n",
    "    # Execute the forward and the backward pass\n",
    "    def run_single_step(self, x, y):\n",
    "        #writer.add_graph(self.sess.graph)\n",
    "        _, loss, recon_loss, latent_loss = self.sess.run(\n",
    "            [self.train_op, self.total_loss, self.recon_loss, self.latent_loss],\n",
    "            feed_dict={self.x: x, self.y: y}\n",
    "           \n",
    "        )\n",
    "      \n",
    "        return loss, recon_loss, latent_loss\n",
    "    \n",
    "    # x -> x_hat\n",
    "    def reconstructor(self, x, y):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.x: x, self.y: y})\n",
    "        return x_hat\n",
    "\n",
    "    # z -> x\n",
    "    def generator(self, z, y):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.z: z, self.y:y})\n",
    "        return x_hat\n",
    "    \n",
    "    # x -> z\n",
    "    def transformer(self, x):\n",
    "        z = self.sess.run(self.z, feed_dict={self.x: x})\n",
    "        return z\n",
    "    \n",
    "    def get_mu_sigma(self, x, y):\n",
    "        mu, sigma = self.sess.run([self.z_mu,self.z_log_sigma_sq], feed_dict={self.x: x, self.y:y})\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVAE_loss_ = []\n",
    "MVAE_recon_loss_=[]\n",
    "MVAE_latent_loss_ = []\n",
    "MVAE_auc_svm_ = []\n",
    "MVAE_auc_dt_ = []\n",
    "MVAE_auc_rf_ = []\n",
    "\n",
    "MVAE_t1_ = []\n",
    "MVAE_t2_ = []\n",
    "MVAE_t3_ = []\n",
    "          \n",
    "def MVAE_trainer(learning_rate=1e-3, batch_size=100, num_epoch=10, hidden_layers = [80, 30, 15]):\n",
    "    path = \"hidden/MVAE/\"\n",
    "    model = MVAE(learning_rate=learning_rate,\n",
    "                                    batch_size=batch_size, hidden_layers=hidden_layers) \n",
    "    for epoch in range(num_epoch):\n",
    "       \n",
    "        num_sample = len (X_train)\n",
    "        for iter in range(num_sample // batch_size):\n",
    "           \n",
    "            X_mb, y_mb = dt.train.next_batch(batch_size)\n",
    "            # Execute the forward and the backward pass and report computed losses\n",
    "            \n",
    "            loss, recon_loss, latent_loss= model.run_single_step(X_mb, y_mb)\n",
    "         \n",
    "        if epoch % step == 0:\n",
    "            print('[Epoch {}] Loss: {}, Recon loss: {}, Latent loss: {}'.format(\n",
    "                epoch, loss, recon_loss, latent_loss))\n",
    "            #model.writer.add_summary(summary, epoch )\n",
    "               \n",
    "            z_train = model.transformer(X_train)\n",
    "            s = time.time()\n",
    "            z_test = model.transformer(X_test)\n",
    "            e = time.time()\n",
    "            t_tr = (e - s)/ float(len(X_test))\n",
    "            np.savetxt(path +  \"z_train_\"+str(epoch)+\".csv\", z_train, delimiter=\",\", fmt='%f' )\n",
    "            np.savetxt(path +  \"z_test_\"+str(epoch)+\".csv\", z_train, delimiter=\",\", fmt='%f' )\n",
    "            \n",
    "\n",
    "            #geo, auc, f1, acc = classifier.Gaussian(z_train, Y_train, z_test,Y_test)\n",
    "            auc_svm, t1 = classifier.svm(z_train, Y_train, z_test,Y_test)\n",
    "            auc_dt, t2 = classifier.decisiontree(z_train, Y_train, z_test,Y_test)\n",
    "            auc_rf, t3 = classifier.rf(z_train, Y_train, z_test,Y_test)\n",
    "           \n",
    "           \n",
    "            MVAE_loss_.append(loss)\n",
    "            MVAE_recon_loss_.append(recon_loss)\n",
    "            MVAE_latent_loss_.append(latent_loss) \n",
    "            MVAE_auc_svm_.append(auc_svm)\n",
    "            MVAE_auc_dt_.append(auc_dt)\n",
    "            MVAE_auc_rf_.append(auc_rf)\n",
    "            MVAE_t1_.append(t1 + t_tr)\n",
    "            MVAE_t2_.append(t2 + t_tr)\n",
    "            MVAE_t3_.append(t3 + t_tr)\n",
    "     \n",
    "    print('Done MVAE!')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE_recon_loss_=[]\n",
    "AE_auc_svm_ = []\n",
    "AE_auc_dt_ = []\n",
    "AE_auc_rf_ = []\n",
    "\n",
    "AE_t1_ = []\n",
    "AE_t2_ = []\n",
    "AE_t3_ = []\n",
    "\n",
    "def AE_trainer(learning_rate=1e-3, batch_size=100, num_epoch=10, hidden_layers = [7,4,2]):\n",
    "    \n",
    "    model1 = AE(learning_rate=learning_rate, batch_size=batch_size, hidden_layers=hidden_layers)\n",
    "    for epoch in range(num_epoch):\n",
    "        \n",
    "        num_sample = len (X_train)\n",
    "        for iter in range(num_sample // batch_size):\n",
    "           \n",
    "            X_mb, _ = dt.train.next_batch(batch_size)\n",
    "            # Execute the forward and the backward pass and report computed losses\n",
    "            recon_loss= model1.run_single_step(X_mb)\n",
    "        \n",
    "        if epoch % step == 0:\n",
    "            print('[Epoch {}] Recon loss: {}'.format(\n",
    "                epoch, recon_loss))\n",
    "            #model.writer.add_summary(summary, epoch )\n",
    "               \n",
    "            z_train = model1.transformer(X_train)\n",
    "            s = time.time()\n",
    "            z_test = model1.transformer(X_test)\n",
    "            e = time.time()\n",
    "            t_tr = (e-s)/float(len(X_test))\n",
    "            #np.savetxt(path +  \"z_train_\"+str(epoch)+\".csv\", z_train, delimiter=\",\", fmt='%f' )\n",
    "            #np.savetxt(path +  \"z_test_\"+str(epoch)+\".csv\", z_train, delimiter=\",\", fmt='%f' )\n",
    "            auc_svm, t1 = classifier.svm(z_train, Y_train, z_test,Y_test)\n",
    "            auc_dt, t2 = classifier.decisiontree(z_train, Y_train, z_test,Y_test)\n",
    "            auc_rf, t3 = classifier.rf(z_train, Y_train, z_test,Y_test)\n",
    "             \n",
    "            AE_recon_loss_.append(recon_loss)\n",
    "            AE_auc_svm_.append(auc_svm)\n",
    "            AE_auc_dt_.append(auc_dt)\n",
    "            AE_auc_rf_.append(auc_rf)\n",
    "            AE_t1_.append(t1 + t_tr)\n",
    "            AE_t2_.append(t2 + t_tr)\n",
    "            AE_t3_.append(t3 + t_tr)\n",
    "       \n",
    "    print('Done AE!')\n",
    "    \n",
    "   \n",
    "    return model1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_recon_loss_=[]\n",
    "MAE_label_loss_=[]\n",
    "MAE_auc_svm_ = []\n",
    "MAE_auc_dt_ = []\n",
    "MAE_auc_rf_ = []\n",
    "\n",
    "MAE_t1_ = []\n",
    "MAE_t2_ = []\n",
    "MAE_t3_ = []\n",
    "\n",
    "def MAE_trainer(learning_rate=1e-3, batch_size=100, num_epoch=10, hidden_layers = [7,4,2]):\n",
    "    path = \"hidden/MAE/\"\n",
    "    model1 = MAE(learning_rate=learning_rate, batch_size=batch_size, hidden_layers=hidden_layers)\n",
    "    for epoch in range(num_epoch):\n",
    "        \n",
    "        num_sample = len (X_train)\n",
    "        for iter in range(num_sample // batch_size):\n",
    "           \n",
    "            X_mb, y_mb = dt.train.next_batch(batch_size)\n",
    "            # Execute the forward and the backward pass and report computed losses\n",
    "            recon_loss, label_loss= model1.run_single_step(X_mb, y_mb)\n",
    "        \n",
    "        if epoch % step == 0:\n",
    "            print('[Epoch {}] Recon loss: {}'.format(\n",
    "                epoch, recon_loss))\n",
    "            #model.writer.add_summary(summary, epoch )\n",
    "               \n",
    "            z_train = model1.transformer(X_train)\n",
    "            s = time.time()\n",
    "            z_test = model1.transformer(X_test)\n",
    "            e = time.time()\n",
    "            t_tr = (e-s)/float(len(X_test))\n",
    "            np.savetxt(path + \"z_train_\"+str(epoch)+\".csv\", z_train, delimiter=\",\", fmt='%f' )\n",
    "            np.savetxt(path +\"z_test_\"+str(epoch)+\".csv\", z_test, delimiter=\",\", fmt='%f' )\n",
    "            auc_svm, t1 = classifier.svm(z_train, Y_train, z_test,Y_test)\n",
    "            auc_dt, t2 = classifier.decisiontree(z_train, Y_train, z_test,Y_test)\n",
    "            auc_rf, t3 = classifier.rf(z_train, Y_train, z_test,Y_test)\n",
    "             \n",
    "           \n",
    "           \n",
    "            MAE_recon_loss_.append(recon_loss)\n",
    "            MAE_label_loss_.append(label_loss)\n",
    "            MAE_auc_svm_.append(auc_svm)\n",
    "            MAE_auc_dt_.append(auc_dt)\n",
    "            MAE_auc_rf_.append(auc_rf)\n",
    "            MAE_t1_.append(t1 + t_tr)\n",
    "            MAE_t2_.append(t2 + t_tr)\n",
    "            MAE_t3_.append(t3 + t_tr)\n",
    "       \n",
    "    print('Done MAE!')\n",
    "    \n",
    "   \n",
    "    return model1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMAE_recon_loss_=[]\n",
    "DMAE_label_loss_=[]\n",
    "DMAE_auc_svm_ = []\n",
    "DMAE_auc_dt_ = []\n",
    "DMAE_auc_rf_ = []\n",
    "\n",
    "DMAE_t1_ = []\n",
    "DMAE_t2_ = []\n",
    "DMAE_t3_ = []\n",
    "\n",
    "def DMAE_trainer(learning_rate=1e-3, batch_size=100, num_epoch=10, hidden_layers = [7,4,2]):\n",
    "    path = \"hidden/DMAE/\"\n",
    "    model1 = DMAE(learning_rate=learning_rate, batch_size=batch_size, hidden_layers=hidden_layers)\n",
    "    for epoch in range(num_epoch):   \n",
    "        num_sample = len (X_train)\n",
    "        for iter in range(num_sample // batch_size):  \n",
    "            X_mb, y_mb = dt.train.next_batch(batch_size)\n",
    "            # Execute the forward and the backward pass and report computed losses\n",
    "            recon_loss, label_loss= model1.run_single_step(X_mb, y_mb)\n",
    "        \n",
    "        if epoch % step == 0:\n",
    "            print('[Epoch {}] Recon loss: {}'.format(\n",
    "                epoch, recon_loss))\n",
    "           \n",
    "            z_train = model1.transformer(X_train)\n",
    "            s = time.time()\n",
    "            z_test = model1.transformer(X_test)\n",
    "            e = time.time()\n",
    "            t_tr = (e-s)/float(len(X_test))\n",
    "            np.savetxt(path + \"z_train_\"+str(epoch)+\".csv\", z_train, delimiter=\",\", fmt='%f' )\n",
    "            np.savetxt(path +\"z_test_\"+str(epoch)+\".csv\", z_test, delimiter=\",\", fmt='%f' )\n",
    "            auc_svm, t1 = classifier.svm(z_train, Y_train, z_test,Y_test)\n",
    "            auc_dt, t2 = classifier.decisiontree(z_train, Y_train, z_test,Y_test)\n",
    "            auc_rf, t3 = classifier.rf(z_train, Y_train, z_test,Y_test)\n",
    "               \n",
    "            DMAE_recon_loss_.append(recon_loss)\n",
    "            DMAE_label_loss_.append(label_loss)\n",
    "            DMAE_auc_svm_.append(auc_svm)\n",
    "            DMAE_auc_dt_.append(auc_dt)\n",
    "            DMAE_auc_rf_.append(auc_rf)\n",
    "            DMAE_t1_.append(t1 + t_tr)\n",
    "            DMAE_t2_.append(t2 + t_tr)\n",
    "            DMAE_t3_.append(t3 + t_tr)\n",
    "       \n",
    "    print('Done DMAE!')\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_auc_tofile(method, svms, dts, rfs, t1s, t2s, t3s):\n",
    "    index1, svm = max(enumerate(svms), key=operator.itemgetter(1))\n",
    "    index2, dt = max(enumerate(dts), key=operator.itemgetter(1))\n",
    "    index3, rf = max(enumerate(rfs), key=operator.itemgetter(1))\n",
    "    \n",
    "    t1 =1000 * sum(t1s)/len(t1s)\n",
    "    t2 =1000 *  sum(t2s)/len(t2s)\n",
    "    t3 =1000 *  sum(t3s)/len(t3s)\n",
    "    \n",
    "\n",
    "    data_save = np.asarray([data_index, input_dim,  svm, dt, rf, t1, t2, t3])   \n",
    "    data_save = np.reshape(data_save, (-1,8))\n",
    "\n",
    "\n",
    "    if os.path.isfile(\"Results/RF_AUC_DIF/AUC_Hidden_\"+method+\".csv\"): #\n",
    "        auc = np.genfromtxt(\"Results/RF_AUC_DIF/AUC_Hidden_\"+method+\".csv\", delimiter=',') \n",
    "        auc = np.reshape(auc,(-1,8))\n",
    "        data_save = np.concatenate((auc, data_save), axis = 0)\n",
    "        np.savetxt(\"Results/RF_AUC_DIF/AUC_Hidden_\"+method+\".csv\", data_save,delimiter = \",\",fmt = \"%f\")\n",
    "    \n",
    "    else:\n",
    "        np.savetxt(\"Results/RF_AUC_DIF/AUC_Hidden_\"+method+\".csv\", data_save,delimiter = \",\",fmt = \"%f\")\n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epoch = 100\n",
    "step = 20\n",
    "\n",
    "hidden_layer = hidden_layers[data_index]\n",
    "block_size = batch_sizes[data_index]\n",
    "lr = 1e-3\n",
    "noise_factor = 0.0025\n",
    "\n",
    "model = MAE_trainer(learning_rate=lr,  batch_size=block_size, num_epoch=num_epoch, hidden_layers = hidden_layer)\n",
    "#save auc to file:\n",
    "save_auc_tofile(\"MAE\", MAE_auc_svm_, MAE_auc_dt_, MAE_auc_rf_,MAE_t1_, MAE_t2_, MAE_t3_)\n",
    "\n",
    "model = DMAE_trainer(learning_rate=lr,  batch_size=block_size, num_epoch=num_epoch, hidden_layers = hidden_layer)\n",
    "#save auc to file:\n",
    "save_auc_tofile(\"DMAE\",DMAE_auc_svm_, DMAE_auc_dt_, DMAE_auc_rf_, DMAE_t1_, DMAE_t2_, DMAE_t3_)\n",
    "\n",
    "model = AE_trainer(learning_rate=lr,  batch_size=block_size, num_epoch=num_epoch, hidden_layers = hidden_layer)\n",
    "##save auc to file:\n",
    "save_auc_tofile(\"AE\", AE_auc_svm_, AE_auc_dt_, AE_auc_rf_,AE_t1_, AE_t2_, AE_t3_)\n",
    "\n",
    "model = MVAE_trainer(learning_rate=lr,  batch_size=block_size, num_epoch=num_epoch, hidden_layers = hidden_layer)\n",
    "##save auc to file:\n",
    "save_auc_tofile(\"MVAE\", MVAE_auc_svm_, MVAE_auc_dt_, MVAE_auc_rf_, MVAE_t1_, MVAE_t2_, MVAE_t3_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
